{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3006a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "\n",
    "# TODO Find a way to turn off that red debugging spam from tensorflow, this does not work\n",
    "tf.get_logger().setLevel('WARN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a68975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Added parameters to match with VGG16 and for augmenting data\n",
    "\n",
    "'''\n",
    "\n",
    "# Global params and constants\n",
    "WIDTH = 600\n",
    "HEIGHT = 600\n",
    "BATCH_SIZE = 50\n",
    "EPOCHS = 2\n",
    "TRAIN_IMAGES_PATH = r'./dataset/train_set_labelled'\n",
    "TEST_IMAGES_PATH = r'./dataset/test_set'\n",
    "TRAIN_LABELS_PATH = r'./dataset/train_labels.csv'\n",
    "PREDICTIONS_PATH = r'predictions.csv'\n",
    "NUM_EXAMPLES = len(list(Path(TRAIN_IMAGES_PATH).rglob('*.jpg')))\n",
    "NUM_CLASSES = len(list(Path(TRAIN_IMAGES_PATH).iterdir()))\n",
    "print(f'Num classes: {NUM_CLASSES}  num samples: {NUM_EXAMPLES}')\n",
    "\n",
    "# Generators allow to get the data in batches without having to worry about the memory\n",
    "train_generator = ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "    rescale = 1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode=\"nearest\"\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True\n",
    ")\n",
    "val_generator = ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "    rescale = 1./255,\n",
    ")\n",
    "\n",
    "train_gen = train_generator.flow_from_directory(\n",
    "    directory=TRAIN_IMAGES_PATH,\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(WIDTH, HEIGHT),\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "validation_gen = val_generator.flow_from_directory(\n",
    "    directory=TRAIN_IMAGES_PATH,\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(WIDTH, HEIGHT),\n",
    "    shuffle=True,\n",
    "    subset='validation'\n",
    ")\n",
    "test_gen = val_generator.flow_from_directory(\n",
    "    directory=TEST_IMAGES_PATH,\n",
    "    class_mode=None,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(WIDTH, HEIGHT),\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "def make_predictions(model: keras.Model, test_gen: ImageDataGenerator):\n",
    "    \"\"\"\n",
    "    Output a CSV with model's predictions on test set that is ready to be submitted to Kaggle.\n",
    "    The file will be created in the main directory of the project, named 'predictions <current_time>'\n",
    "    \"\"\"\n",
    "    predictions = model.predict(test_gen, verbose=True, batch_size=BATCH_SIZE)\n",
    "    # Get names of test files in the same order they were used for predictions\n",
    "    file_names = list(map(lambda x: x.split('\\\\')[1], test_gen.filenames))\n",
    "    # Obtain final labels for predictions, add one since classes start from one\n",
    "    predictions = predictions.argmax(axis=1) + 1\n",
    "    result = pd.DataFrame({'img_name': file_names, 'label': predictions})\n",
    "    result = result.set_index('img_name')\n",
    "    # Save the CSV file to main project directory\n",
    "    result.to_csv(f'predictions {datetime.datetime.now().strftime(\"%d-%m-%Y %Hh %Mm %Ss\")}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ca045",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Import the VGG16 library and add preprocessing layer to the front of VGG\n",
    "''' \n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB7\n",
    "from keras.models import Model\n",
    "\n",
    "effB7 = EfficientNetB7(input_shape=[600,600,3], include_top=False, weights=\"imagenet\")\n",
    "\n",
    "# VGG16(input_shape=[224, 224, 3], weights='imagenet', include_top=False)\n",
    "\n",
    "# to not train existing weights\n",
    "for layer in effB7.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# our layers - you can add more if you want\n",
    "x = Flatten()(effB7.output)\n",
    "\n",
    "pred = Dense(80, activation='softmax')(x)\n",
    "    \n",
    "model = Model(inputs=effB7.input, outputs=pred)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    train_gen,\n",
    "    validation_data=validation_gen,\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_steps=len(validation_gen),\n",
    "    epochs=EPOCHS,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "make_predictions(model=model, test_gen=test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ac8aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
